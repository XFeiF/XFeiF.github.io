<!DOCTYPE html>
<html >
	<head>
		<meta charset="utf-8">
		<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<meta name="author" content="XFeiF">
		<meta name="description" content="XFeiFçš„ç‹¬ç«‹åšå®¢">
		<meta name="generator" content="Hugo 0.69.2" />
		<title>DataParallel vs DistributedDataParallel &middot; </title>
		<link rel="shortcut icon" href="https://blog.x-fei.me/images/favicon.ico">
		<link rel="stylesheet" href="https://blog.x-fei.me/css/style.css">
		
		
		
		

		

		
		<link href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

<link href="https://cdn.staticfile.org/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<script src="https://cdn.staticfile.org/highlight.js/9.12.0/highlight.min.js"></script>
<script>
    hljs.initHighlightingOnLoad();
</script>
<script type="text/javascript" async src="https://cdn.staticfile.org/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [
                ['$', '$'],
                ['\\(', '\\)']
            ],
            displayMath: [
                ['$$', '$$'],
                ['\[\[', '\]\]']
            ],
            processEscapes: true,
            processEnvironments: true,
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            TeX: {
                equationNumbers: {
                    autoNumber: "AMS"
                },
                extensions: ["AMSmath.js", "AMSsymbols.js"]
            }
        }
    });

    MathJax.Hub.Queue(function() {
        
        
        
        var all = MathJax.Hub.getAllJax(),
            i;
        for (i = 0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
    MathJax.Hub.Config({
        CommonHTML: {
            linebreaks: {
                automatic: true
            }
        },
        "HTML-CSS": {
            linebreaks: {
                automatic: true
            }
        },
        SVG: {
            linebreaks: {
                automatic: true
            }
        }
    });
</script>

<style>
    code.has-jax {
        font: inherit;
        font-size: 100%;
        background: inherit;
        border: inherit;
        color: #515151;
    }
</style>


<script src="https://cdn.staticfile.org/jquery/1.8.3/jquery.js"></script>
<script src="https://cdn.staticfile.org/jquery.imagesloaded/2.1.0/jquery.imagesloaded.js"></script>
<script src="https://cdn.staticfile.org/masonry/4.2.2/masonry.pkgd.min.js"></script>
<script src="https://cdn.staticfile.org/bigfoot/2.1.4/bigfoot.min.js"></script>
<link href="https://cdn.staticfile.org/bigfoot/2.1.4/bigfoot-default.min.css" rel="stylesheet">
	</head>


<body>
    <div class="nav-header nav-header-fixed animated">
    <a href="https://blog.x-fei.me/" class="left swing">
        <img src="https://blog.x-fei.me/images/Feiaaa.png" alt="" class="icon rounded">
    </a>
</div>

 
<header id="header" class="blog-background banner-mask lazy no-cover" style="display: table; background-image: url(https://raw.githubusercontent.com/XFeiF/Photos/master/blog/pytorch.jpg);">
    <div class="header-wrap site-nav">
    <div class="home-info-container">
        <a href="https://blog.x-fei.me/">
            <h2>Do not go gentle into that good night</h2>
        </a>
    </div>
    <div class="nav-header-container">
        <ul class="links">
            <li class="nav-blog">
                <a href='https://blog.x-fei.me/'> Home</a>
            </li>
            <li>
                <a href='https://blog.x-fei.me/archives'>Archives</a>
            </li>
            <li>
                <a href='https://blog.x-fei.me/timelines'>Timelines</a>
            </li>
            <li>
                <a href='https://blog.x-fei.me/friends'>Friends</a>
            </li>
            <li>
                <a href='https://blog.x-fei.me/about'>About</a>
            </li>
        </ul>


    	

    	
    </div>
</div>

</header>
 
    <div id="main">
        <article class="page-template page-index container-wrapper">
            <div class="post-card">
                <div class="post-container">
                    <div class="post-header">
                        <div class="meta">
                            <h1 id="post-title">DataParallel vs DistributedDataParallel</h1>
                            
                            
                                <time datetime="2020-11-04">Nov 4, 2020</time>
                            
                            <span class="categories">
                                 on 
    
        <a class="badge badge-primary" href="/categories/machine-learning">Machine Learning</a>
    


                            </span> - 1 min read.

                        </div>
                    </div>
                    <div class="post-content">
                        <div id="toc" class="">

                        </div>
                        <div class="inner-content">
                            <p>å¤šå¡è®­ç»ƒæ¨¡å‹æ—¶ç»•ä¸è¿‡çš„ä¸€ä¸ªé—®é¢˜ï¼š<code>DataParallel</code>(DP)å’Œ<code>DistributedDataParallel</code>(DDP)æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ<br />
å•æœºå•å¡ä¸ç”¨è€ƒè™‘ã€‚<br />
å¤šæœºå¤šå¡ç”¨DDPä¹Ÿä¸ç”¨å¤šæƒ³ã€‚<br />
å•æœºå¤šå¡ç”¨DPå’ŒDDPæœ‰å•¥åŒºåˆ«ï¼Ÿä¸ºä»€ä¹ˆDDPæ¯”DPè¦å¿«ï¼Ÿ</p>

<hr />

<p>PSï¼šå…³äºå¹³è¡Œä¸åˆ†å¸ƒå¼è®­ç»ƒï¼Œpytorchå®˜ç½‘çš„tutorialé‡Œæœ‰è¯¦ç»†çš„ä¸€ç« èŠ‚æè¿°ï¼Œå»ºè®®å»çœ‹çœ‹ã€‚æœ¬æ–‡ç”¨ä¸­æ–‡åšä¸€ä¸ªç®€çŸ­çš„æ€»ç»“ä¸è§£é‡Šã€‚</p>

<h3 id="èµ·æº">èµ·æº</h3>

<p>é¦–å…ˆï¼Œè¿™ä¸ªé—®é¢˜èµ·æºäºpytorchçš„<a href="https://pytorch.org/docs/stable/nn.html#torch.nn.DataParallel"> <code>torch.nn.DataParallel</code> </a>æ–‡æ¡£ä¸­çš„ä¸€æ®µè­¦å‘Šï¼š</p>

<blockquote>
<p>This is the highly recommended way to use <code>DistributedDataParallel</code> , with multiple processes, each of which operates on a single GPU. This is currently the fastest approach to do data parallel training using PyTorch and applies to both single-node(multi-GPU) and multi-node data parallel training. It is proven to be significantly faster than DataParallel for single-node multi-GPU data parallel training.</p>
</blockquote>

<p>DPåº”è¯¥æ˜¯å†å²é—ç•™ï¼Œå¹¶éä¸€å¼€å§‹è®¾è®¡å‡ºæ¥å°±æ˜¯è¢«æ‰“è„¸çš„ã€‚</p>

<h3 id="è§£é‡Š">è§£é‡Š</h3>

<p>DDP æ˜¯<strong>å¤šè¿›ç¨‹å¹¶è¡Œ</strong>æ¨¡å¼ï¼Œè¿™å°±ä½¿å¾—DDPå¯ä»¥åœ¨ä¸åŒçš„è®¡ç®—æœºä¸Šè¿è¡Œã€‚</p>

<p>è€ŒDPæ˜¯<strong>å•è¿›ç¨‹å¤šçº¿ç¨‹å¹¶è¡Œ</strong>æ¨¡å¼ã€‚å› æ­¤å®ƒåªèƒ½åœ¨å•ä¸ªè®¾å¤‡ä¸Šè¿è¡Œã€‚</p>

<p>ç°åœ¨é—®é¢˜å˜å¾—å¾ˆç®€å•ï¼ŒDDPå’ŒDPçš„åŒºåˆ«å¯ä»¥ç†è§£ä¸º<strong>å¤šè¿›ç¨‹</strong>å’Œ<strong>å¤šçº¿ç¨‹</strong>ä¹‹é—´çš„åŒºåˆ«ï¼Œè¿™æ˜¯æœ¬ç§‘ç”Ÿé¢è¯•å¸¸è¢«é—®åˆ°çš„æ“ä½œç³»ç»Ÿç›¸å…³çš„é—®é¢˜ã€‚ç½‘ç»œä¸Šæœ‰å¾ˆå¤šè§£é‡Šã€‚ç®€å•æ¥è¯´çº¿ç¨‹æ˜¯è¿›ç¨‹çš„ä¸€éƒ¨åˆ†ï¼Œä¸€ä¸ªè¿›ç¨‹å¯ä»¥æœ‰å¤šä¸ªçº¿ç¨‹ï¼Œä¸€ä¸ªè¿›ç¨‹å†…çš„å¤šä¸ªçº¿ç¨‹è¦é€šè¿‡æŠ¢æ‰§è¡Œæƒè·å¾—æ‰§è¡Œæ—¶é—´ã€‚</p>

<p>è¿™é‡Œæä¸€ä¸‹æˆ‘ä¹‹å‰çš„ä¸€ç¯‡åšå®¢<a href="https://blog.x-fei.me/posts/py/gil_in_python/">GIL in Python</a>ï¼Œæˆ‘è§£é‡Šè¿‡çº¿ç¨‹ä¸‹é¢çº¿ç¨‹çš„æ‰§è¡Œæ–¹å¼ï¼š</p>

<blockquote>
<ol>
<li>è·å–GILï¼›</li>
<li>æ‰§è¡Œä»£ç ç›´åˆ°sleepæˆ–è€…Pythonè™šæ‹Ÿæœºå°†å…¶æŒ‚èµ·ï¼›</li>
<li>é‡Šæ”¾GIL</li>
</ol>
</blockquote>

<p>ä¸€ä¸ªpythonè¿›ç¨‹åªæœ‰ä¸€ä¸ªGILï¼Œçº¿ç¨‹è¦æŠ¢åˆ°GILæ‰èƒ½è¢«CPUæ‰§è¡Œã€‚</p>

<p>å›åˆ°DPå’ŒDDPçš„é—®é¢˜ä¸Šã€‚ç”±äºDPæ˜¯å•è¿›ç¨‹çš„ï¼Œ<strong>è·¨å¤šä¸ªçº¿ç¨‹çš„GILç«äº‰ä»¥åŠæ¯æ¬¡è¿­ä»£åˆ†æ•£æ•°æ®å’Œæ”¶é›†æ•°æ®ä»¥åŠæ¨¡å‹å¤åˆ¶ä¼šå¸¦æ¥é¢å¤–çš„å¼€é”€</strong>ã€‚è¿™å°±å¯¼è‡´äº†å³ä½¿æ˜¯å•æœºå¤šå¡ï¼ŒDPä¹Ÿæ¯”DDPæ…¢ã€‚</p>

<p>å…·ä½“åœ°ï¼Œåœ¨å•æœºå¤šå¡ç¯å¢ƒä¸‹ï¼ŒDDPçš„ä¼˜ç‚¹ï¼š</p>

<ol>
<li>æ¯ä¸ªè¿›ç¨‹éƒ½æœ‰è‡ªå·±çš„optimizerï¼Œæ¯æ¬¡è¿­ä»£éƒ½è¿›è¡Œå®Œæ•´çš„ä¼˜åŒ–æ­¥éª¤ã€‚ç”±äºæ¢¯åº¦å·²ç»åœ¨å„ä¸ªè¿›ç¨‹ä¸­æ”¶é›†èµ·æ¥å¹¶ä½œäº†å¹³å‡ï¼Œæ‰€ä»¥è¿™å¯¹æ¯ä¸ªè¿›ç¨‹éƒ½æ˜¯ç›¸åŒçš„ï¼ˆæ€»å…±æ“ä½œä¸€æ¬¡ï¼‰ï¼Œå°±ä¸å†éœ€è¦å‚æ•°ä¼ æ’­ï¼ŒèŠ‚çº¦äº†èŠ‚ç‚¹é—´ä¼ é€’å¼ é‡çš„æ—¶é—´ã€‚</li>
<li>æ¯ä¸ªè¿›ç¨‹éƒ½æœ‰è‡ªå·±çš„pythonè§£é‡Šå™¨ï¼Œä»è€Œæ¶ˆé™¤äº†ç”±å•ä¸ªpythonè¿›ç¨‹é©±åŠ¨å¤šä¸ªæ‰§è¡Œçº¿ç¨‹ï¼Œæ¨¡å‹å‰¯æœ¬æˆ–GPUæ‰€å¸¦æ¥çš„é¢å¤–è§£é‡Šå™¨å¼€é”€ä»¥åŠGILç«äº‰é—®é¢˜ã€‚è¿™å¯¹é‚£äº›åŒ…å«å¾ªç¯å±‚æˆ–è®¸å¤šå°ç»„ä»¶ï¼Œå³ä½¿ç”¨python runtimeå¾ˆå¤šçš„æ¨¡å‹ååˆ†é‡è¦ã€‚</li>
</ol>

<h3 id="ç”¨æ³•">ç”¨æ³•</h3>

<h4 id="dataparallel">DataParallel</h4>

<p>DPçš„ä½¿ç”¨ååˆ†ç®€å•ï¼Œä¸€è¡Œä»£ç è§£å†³ã€‚</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-PYTHON" data-lang="PYTHON">net <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>DataParallel(model, device_ids<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>])	</code></pre></div>
<p>æ³¨æ„ï¼Œæ— è®ºæ˜¯ä½¿ç”¨äº†DPè¿˜æ˜¯DDPï¼Œæ¨¡å‹éƒ½ä¼šå‡æ ¼ï¼ŒåŸæ¨¡å‹æˆä¸ºå½“å‰æ¨¡å‹çš„ä¸€ä¸ª<code>module</code>ï¼Œå³<code>net = net.module</code>ã€‚æ‰€ä»¥å¦‚æœä¸ä¿®æ”¹æ¨¡å‹ä¿å­˜æ—¶çš„ä»£ç ï¼Œåœ¨load pretrainçš„æ—¶å€™ï¼Œéœ€è¦æ³¨æ„è¿™ä¸€ç‚¹ï¼Œå¦åˆ™ä¼šå‡ºç°å‚æ•°keyä¸åŒ¹é…é—®é¢˜ã€‚</p>

<h4 id="distributeddataparallel">DistributedDataParallel</h4>

<p>å®˜æ–¹æœ‰ä¸€ä¸ªè¯¦ç»†çš„tutorialï¼Œ<a href="https://pytorch.org/tutorials/intermediate/ddp_tutorial.html#:~:text=Comparison%20between%20DataParallel%20and%20DistributedDataParallel&amp;text=First%2C%20DataParallel%20is%20single%2Dprocess,%2D%20and%20multi%2D%20machine%20training.">è¯¦æƒ…</a>
<br></p>
                        </div>
                    </div>
                    
                    <div class="post-tags">
                        <span># Tags: </span>
                            
                                <a class="badge badge-primary" href="/tags/pytorch">PyTorch</a>
                            
                    </div>
                    
                    <nav class="post-related">
                            

    <a rel="prev" id="prev-btn" class="btn hvr-grow" href="/posts/ml/pytorch_nn_module/"> &laquo; Pytorch_nn_module</a>


    <a rel="next" id="next-btn" class="btn hvr-grow" href="/posts/ml/pytorch_non_blocking/">Pytorchä¸­çš„non_blocking &raquo;</a>


                    </nav>
                    <footer class="comments">
                        <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "xfeif" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
                    </footer>
                </div>
            </div>

        </article>
    </div>
    <a id="rocket" href="#top" class=""></a>
<script type="text/javascript" src="https://blog.x-fei.me/js/totop.js"></script>
<footer id="footer" class='site-footer'>
    
    <section class="footer">
    
       ğŸ“<a href="https://blog.x-fei.me">XFeiF</a> Â© 2015-2020 <i class="fa fa-heart" aria-hidden="true"></i>
    
    </section>
    <section>
        Theme Fx <a href="https://github.com/XFeiF" class="github-repo"><span class="gadget-github"></span>Star</a>
        Designed By <a href="https://github.com/XFeiF">@XFeiF</a>
    </section>
    <section class="poweredby">
        Powered by <a href="http://www.gohugo.io/">Hugo</a>
    </section>
</footer>

</body>
</html>
