<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on </title>
    <link>https://xfeif.github.io/tags/machine-learning/</link>
    <description>Recent content in Machine Learning on </description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Fri, 14 Jun 2019 21:21:56 +0800</lastBuildDate>
    
	<atom:link href="https://xfeif.github.io/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>闲聊Activation Functions</title>
      <link>https://xfeif.github.io/posts/ml/activationfunctions/</link>
      <pubDate>Fri, 14 Jun 2019 21:21:56 +0800</pubDate>
      
      <guid>https://xfeif.github.io/posts/ml/activationfunctions/</guid>
      <description>&lt;p&gt;最近学习突然想到一些基本的问题，比如“为什么有那么多的激活函数？”，“这些激活函数背后的原理分别是什么？”，以及“什么时候用哪个激活函数效果更好？或者更能达到我们预期想要的结果。” “激活函数里面都是硬核的数学知识吗？”针对这些问题，重新把激活函数相关的内容学习了一下。&lt;br /&gt;
希望本文也可以帮助到对上面这些问题感到困惑、想不全、有些地方不太理解的小伙伴。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>1x1卷积的作用</title>
      <link>https://xfeif.github.io/posts/ml/1x1_convolution/</link>
      <pubDate>Thu, 14 Mar 2019 17:49:58 +0800</pubDate>
      
      <guid>https://xfeif.github.io/posts/ml/1x1_convolution/</guid>
      <description>&lt;p&gt;我们在&lt;code&gt;ResNet&lt;/code&gt;深层结构以及&lt;code&gt;Inception&lt;/code&gt;中都见过&lt;code&gt;1x1&lt;/code&gt;卷积层，或者说&lt;code&gt;bottleneck layer&lt;/code&gt;，为什么我们会需要&lt;code&gt;1x1&lt;/code&gt;的卷积核呢？&lt;br /&gt;
总的来说&lt;code&gt;1x1&lt;/code&gt;卷积可以用作升降维度、减少参数量和计算量、增加非线性特征的作用。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>GD &amp; SGD 理解与二维模拟</title>
      <link>https://xfeif.github.io/posts/ml/gd-sgd-%E7%90%86%E8%A7%A3%E4%B8%8E%E4%BA%8C%E7%BB%B4%E6%A8%A1%E6%8B%9F/</link>
      <pubDate>Wed, 10 Oct 2018 21:12:56 +0800</pubDate>
      
      <guid>https://xfeif.github.io/posts/ml/gd-sgd-%E7%90%86%E8%A7%A3%E4%B8%8E%E4%BA%8C%E7%BB%B4%E6%A8%A1%E6%8B%9F/</guid>
      <description>&lt;p&gt;&lt;strong&gt;&lt;center&gt;Machine Learning Exercise 2&lt;/center&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;实验题目&#34;&gt;实验题目&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;Generate n = 2,000 points uniformly at random in the two-dimensional unit square. Which point do you expect the centroid to be?&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;What objective does the centroid of the points optimize?&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Apply gradient descent (GD) to find the centroid.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Apply stochastic gradient descent (SGD) to find the centroid. Can you
say in simple words, what the algorithm is doing?&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>多项式拟合-线性回归</title>
      <link>https://xfeif.github.io/posts/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92-%E5%A4%9A%E9%A1%B9%E5%BC%8F%E6%8B%9F%E5%90%88/</link>
      <pubDate>Mon, 24 Sep 2018 23:24:56 +0800</pubDate>
      
      <guid>https://xfeif.github.io/posts/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92-%E5%A4%9A%E9%A1%B9%E5%BC%8F%E6%8B%9F%E5%90%88/</guid>
      <description>&lt;p&gt;&lt;strong&gt;&lt;center&gt;Machine Learning Exercise 1&lt;/center&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;实验题目&#34;&gt;实验题目&lt;/h3&gt;

&lt;p&gt;编写程序:模拟仿真多项式回归
参见 textbook p4-12(PRML)。完成以下任务:&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>训练网络管理实验的科学探索💪🏼</title>
      <link>https://xfeif.github.io/posts/%E8%AE%AD%E7%BB%83%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%AE%9E%E9%AA%8C%E7%9A%84%E7%A7%91%E5%AD%A6%E6%8E%A2%E7%B4%A2/</link>
      <pubDate>Sun, 26 Aug 2018 11:26:49 +0800</pubDate>
      
      <guid>https://xfeif.github.io/posts/%E8%AE%AD%E7%BB%83%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%AE%9E%E9%AA%8C%E7%9A%84%E7%A7%91%E5%AD%A6%E6%8E%A2%E7%B4%A2/</guid>
      <description>&lt;p&gt;👏🏼 Some tips about how to manage your experiments！👏🏼&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;无论是打比赛还是写论文，我们都需要做大量的实验。有人说深度调参是“玄学”，为了有效探索这门玄学，需要对模型的结构、参数、结果做全面详尽的记录，对实验结果、模型参数进行合理保存。这里，分享一些我以及我的师兄教给我的在训练网络并科学管理实验方面的一些心得体会。✍🏼&lt;/p&gt;
&lt;/blockquote&gt;</description>
    </item>
    
  </channel>
</rss>